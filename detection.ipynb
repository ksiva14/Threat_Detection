{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threat Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.cm as cm\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "import skimage.io\n",
    "import imageio\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "# plt.rcParams['figure.figsize'] = [20, 20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Functions\n",
    "\n",
    "#### NCC Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAverageRGBN(image):\n",
    "  \"\"\"\n",
    "  Given np Image, return average value of color as (r, g, b)\n",
    "  \"\"\"\n",
    "  # get image as numpy array\n",
    "  # get shape\n",
    "  w,h,d = image.shape\n",
    "  # change shape\n",
    "  image = image.reshape(w*h, d)\n",
    "  # get average\n",
    "  return (np.mean(image, axis=0))\n",
    "# NCC\n",
    "# assume templateDiffs are a cube of differences in x,y,rgb plane\n",
    "def ncc(templateDiffs, templateStd, patchIm):\n",
    "    nRGB = templateDiffs.shape[2]\n",
    "    patchMeans = getAverageRGBN(patchIm)#np.zeros(nRGB)\n",
    "    patchStd = np.zeros(nRGB)\n",
    "    nPixels = templateDiffs.shape[0] * templateDiffs.shape[1]\n",
    "    for color in range(templateDiffs.shape[2]): # get rgb\n",
    "        patchStd[color] = np.std(patchIm[:,:,color],ddof=1) # unbiased\n",
    "    NCC = 0\n",
    "    # get differences, all vectorized because otherwise it's too slow without C mappings.\n",
    "    patchDiffs = np.zeros(patchIm.shape)\n",
    "    for c in range(nRGB):\n",
    "        patchDiffs[:, :, c] = patchIm[:,:,c] - patchMeans[c]\n",
    "    NCC = np.multiply(patchDiffs, templateDiffs)\n",
    "    for c in range(nRGB):\n",
    "      denom = templateStd[c] * patchStd[c] # standard deviation term\n",
    "      NCC[:,:,c] = np.divide(NCC[:,:,c], denom)\n",
    "    \n",
    "    NCC /= (nPixels - 1) \n",
    "    NCC = np.sum(NCC)\n",
    "    return NCC\n",
    "  \n",
    "def ncc_scan(im, templateIm):\n",
    "  windowRows = templateIm.shape[0]\n",
    "  windowCols = templateIm.shape[1]\n",
    "  finalOriginRow = im.shape[0] - windowRows + 1\n",
    "  finalOriginCol = im.shape[1] - windowCols + 1\n",
    "  bestOriginRow = 0\n",
    "  bestOriginCol = 0\n",
    "  bestDistance = -np.Inf\n",
    "  allNCCs = np.zeros((finalOriginRow, finalOriginCol))\n",
    "  \n",
    "  templateMeans = np.zeros(templateIm.shape[2])\n",
    "  templateStd = np.zeros(templateIm.shape[2])\n",
    "  templateDiffs = np.zeros(templateIm.shape)\n",
    "  for color in range(templateIm.shape[2]):\n",
    "    templateMeans[color] = np.mean(templateIm[:,:,color])\n",
    "    templateStd[color] = np.std(templateIm[:,:,color],ddof=1)\n",
    "  for c in range(templateIm.shape[2]):  \n",
    "    templateDiffs[:,:,c] = templateIm[:,:,c] - templateMeans[c]\n",
    "  for row in range(finalOriginRow):\n",
    "      for col in range(finalOriginCol):\n",
    "          candidatePatch = im[row:(row + windowRows), col:(col+windowCols),:]\n",
    "          nccScore = ncc(templateDiffs, templateStd, candidatePatch)\n",
    "          allNCCs[row, col] = nccScore\n",
    "          if nccScore > bestDistance:\n",
    "              bestOriginRow = row\n",
    "              bestOriginCol = col\n",
    "              bestDistance = nccScore\n",
    "  return allNCCs, (bestOriginRow, bestOriginCol) # return a matrix of all the distances and best row/col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meanshift Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelFeature(im, row, col): # reminder row = y, column = x\n",
    "    x = np.zeros(5)\n",
    "    x[0] = col\n",
    "    x[1] = row \n",
    "    x[2] = im[row,col,0] # R\n",
    "    x[3] = im[row,col,1] # G\n",
    "    x[4] = im[row,col,2] # B\n",
    "    return x\n",
    "\n",
    "# centerX ~ col, centerY ~ row\n",
    "def radialDistance(centerX, centerY,x,y):\n",
    "    return np.sqrt( np.square(centerX - x) + np.square(centerY - y))\n",
    "\n",
    "# Epanchnikov profile, also again, x is a column, y is a row (BE VERY CAREFUL)\n",
    "def circularNeighbors(img, x, y, radius):\n",
    "    neighborhood = [] # we will append and then  return a matrix.\n",
    "    maxY = y + radius # max row \n",
    "    minY = y - radius # minimum row\n",
    "    maxX = x + radius # maximum col we're seaching\n",
    "    minX = x - radius # min col\n",
    "    # in case we run into weird boundaries of images\n",
    "    minY = int(minY) - 1\n",
    "    maxY = int(maxY) + 1\n",
    "    minX = int(minX) - 1\n",
    "    maxX = int(maxX) + 1\n",
    "    if minY < 0:\n",
    "        minY = 0\n",
    "    if maxY > img.shape[0]:\n",
    "        maxY = img.shape[0]\n",
    "    if minX < 0:\n",
    "        minX = 0\n",
    "    if maxX > img.shape[1]:\n",
    "        maxX = img.shape[1]\n",
    "    \n",
    "    # note that the way this neighborhood matrix will be sorted from top\n",
    "    # to bottom, left to right. We do the above to reduce computational time.\n",
    "    for row in range(minY, maxY): # y are the rows\n",
    "        for col in range(minX, maxX): # again X are the columns\n",
    "            if radialDistance(centerX=x,centerY=y,x=col,y=row) < radius:\n",
    "                # returns <x,y,r,g,b>\n",
    "                neighborFeatures = pixelFeature(img, row, col)\n",
    "                neighborhood.append(neighborFeatures)\n",
    "    neighborhood = np.stack(neighborhood, axis=0)\n",
    "    return neighborhood\n",
    "\n",
    "def epKernel(centerX, centerY, x, y, h):\n",
    "    r = np.sqrt(np.square(centerX - x) + np.square(centerY - y)) / h\n",
    "    r = np.square(r)\n",
    "    retVal = 0\n",
    "    if r < 1:\n",
    "        retVal = 1 - r\n",
    "    return retVal\n",
    "\n",
    "def colorHistogram(X, bins, x, y, h):\n",
    "    hist = np.zeros((bins,bins,bins)) # CUBE OF BINS for RGB\n",
    "    binUpperBounds = np.zeros(bins) # vectors of bin bounds for each dimension.\n",
    "    binLowerBounds = np.zeros(bins) # indexed in a convenient way.\n",
    "    # compute bin bounds, and since all RGB values are ints, we can >=,<=\n",
    "    for i in range(bins):\n",
    "        low = np.floor(255*i/ bins)\n",
    "        up = np.floor(255*(i+1)/bins)\n",
    "        binLowerBounds[i] = low\n",
    "        binUpperBounds[i] = up\n",
    "        if i > 0:\n",
    "            binLowerBounds[i]+=1\n",
    "    # now go through all the pixel values in X, and bin them. 2 for the position x,y\n",
    "    for i in range(X.shape[0]):\n",
    "        rgbBins = np.zeros(X.shape[1] - 2) # find out which bin each pixel value goes into\n",
    "        for bin in range(bins): # indexed as r,g,b\n",
    "            for color in range(2, X.shape[1]):\n",
    "                if (X[i,color] >= binLowerBounds[bin]) and (X[i,color] <= binUpperBounds[bin]): \n",
    "                    rgbBins[color - 2] = bin # tldr; find bin for rgb colors.\n",
    "        # once binned, then, add their weighted values given center\n",
    "        # using Epanechnikov kernel\n",
    "        # since we defined which ones exist already, we can just add those specifically.\n",
    "        hist[int(rgbBins[0]), int(rgbBins[1]), int(rgbBins[2])] += epKernel(x,y,X[i,0],X[i,1],h)\n",
    "    hist /= np.sum(hist) # normalize\n",
    "    return hist\n",
    "\n",
    "def meanshiftWeights(X, q_model, p_test, bins):\n",
    "    w = np.zeros(X.shape[0])\n",
    "    binUpperBounds = np.zeros(bins) # vectors of bin bounds for each dimension.\n",
    "    binLowerBounds = np.zeros(bins) # indexed in a convenient way.\n",
    "    # compute bin bounds, and since all RGB values are ints, we can >=,<=\n",
    "    for i in range(bins):\n",
    "        low = np.floor(255*i/ bins)\n",
    "        up = np.floor(255*(i+1)/bins)\n",
    "        binLowerBounds[i] = low\n",
    "        binUpperBounds[i] = up\n",
    "        if i > 0:\n",
    "            binLowerBounds[i]+=1\n",
    "    # now let's compute all the weights and get the exact bin for each X-term\n",
    "    for i in range(X.shape[0]):\n",
    "        rgbBins = np.zeros(X.shape[1] - 2) # find out which bin each pixel value goes into\n",
    "        for bin in range(bins): # indexed as r,g,b\n",
    "            for color in range(2, X.shape[1]):\n",
    "                if X[i,color] >= binLowerBounds[bin] and X[i,color] <= binUpperBounds[bin]: \n",
    "                    rgbBins[color - 2] = int(bin) # tldr; find bin for rgb colors.\n",
    "        ratio = q_model[int(rgbBins[0]), int(rgbBins[1]), int(rgbBins[2])]\n",
    "        ratio /= p_test[int(rgbBins[0]), int(rgbBins[1]), int(rgbBins[2])]\n",
    "        ratio = np.sqrt(ratio)\n",
    "        w[i] += ratio\n",
    "        \n",
    "    return w  \n",
    "\n",
    "\n",
    "def mean_shift_track(nextIm, q_model, r, h, initialX, initialY, nIter, epsilon=-1):\n",
    "    bins = q_model.shape[0]\n",
    "    # step 1 generate target pu in current frame at y0\n",
    "    y0 = np.array([initialX, initialY])\n",
    "    euclideanDistance = 0\n",
    "    for iter in range(nIter):\n",
    "        p_X = circularNeighbors(nextIm, y0[0], y0[1], r)\n",
    "        p_test = colorHistogram(p_X, bins, y0[0], y0[1], h)\n",
    "        # compute weights wi\n",
    "        w = meanshiftWeights(p_X, q_model, p_test, bins)\n",
    "        sumW = np.sum(w)\n",
    "        # now compute next best location of target\n",
    "        weightedCoordinates = np.zeros(2)\n",
    "        for i in range(p_X.shape[0]):\n",
    "            weightedCoordinates+= w[i] * p_X[i,:2]\n",
    "        # follow the y1 algorithm\n",
    "        y1 = weightedCoordinates / sumW\n",
    "        euclideanDistance = np.linalg.norm(y1 - y0)\n",
    "        y0 = y1\n",
    "        # stop if y1 - y0 < epsilon, no epsilon here though.\n",
    "        if epsilon > 0 and euclideanDistance < epsilon:\n",
    "            return y0, euclideanDistance\n",
    "    return y0, euclideanDistance\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture( 'data/karthick_john.MOV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    " \n",
    "images = []\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "  ret, frame = cap.read()\n",
    "  if ret == True:\n",
    " \n",
    "    images.append(frame)\n",
    " \n",
    "  # Break the loop\n",
    "  else: \n",
    "    break\n",
    " \n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "imageio.mimsave('firstVideo.gif', images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SegmentLocal](firstVideo.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123, 1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "firstVideo = np.array(images)\n",
    "print(firstVideo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template Match Detection (NCC) - Overlay a red box around the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meanshift Tracking - Continuously Track After The First Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Points, People Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('PytorchBasics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d67f9c819f1245d39383cf14027afb44a89c9a91dd93617a62572f60583be1bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
